{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4311eeed",
   "metadata": {},
   "source": [
    "# **Fraud Detection using an ensemble technique - Intel optimized DBSCAN clustering followed by Light Gradient Boosted Model (LGBM)**\n",
    "\n",
    "To run the following Stock instructions from the Notebook, the kernel should be set to **[conda env:FraudDetection_stock]**. To set the Notebook to the correct kernel, you can do it by running the following cell (the cell will remain in * but you can continue with the process) or you can do the change manually by selecting **Kernel > Change kernel > Python [conda env:FraudDetection_stock]** on the Notebook’s top menu bar. If the correct kernel was selected, you should be able to see the selected kernel's name on the right side of the Notebook menu bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ba857",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.restart({kernel_name: \"conda-env-FraudDetection_stock-py\"}) \n",
    "element.text('Stock kernel loaded. You can continue executing the next cells.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7007a2c",
   "metadata": {},
   "source": [
    "If you want to run the Stock instructions from a terminal instead of the Notebook, you should follow the commands described on the [README.md](README.md#setting-up-stock-environment) file on the section **Setting up Stock Environment** and activate the **FraudDetection_stock** environment. Copy and paste from the markdown sections to the terminal the commands from this Notebook that run the scripts using the python interpreter, e.g. \"python ./src/run_benchmarks_train.py -l ./logs/stock_training.log\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1cc7a",
   "metadata": {},
   "source": [
    "### **Data Ingestion**\n",
    "\n",
    "Please download the data using the instructions provided in the [/data](data/data_download_instructions.txt) folder and save it as creditcard.csv in the same location. The dataset has details of more than 280,000 credit card transactions with 30 columns serve as the features for model build and a \"Class\" label of 0 (legitimate transaction) and 1 (fraudulent transaction). The data is read as a pandas dataframe and split into train/test portions in the training and hyperparameter tuning scripts. The training set will be used clustering and LGBM training whereas the test set will be used as \"new\" data for inference while evaluating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15222a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once downloaded\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/creditcard.csv\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74f3e6",
   "metadata": {},
   "source": [
    "### **Stock Clustering + Training/Hyperparameter Tuning**\n",
    "\n",
    "The clustering and training portion of the benchmarking can be run using the python script `run_benchmarks_train.py`. The script **reads data**, **performs DBSCAN clustering** and filters data belonging to a cluster which has the maximum proportion of fraudulent transactions.\n",
    "\n",
    "The script then **trains an LGBM model** on the full dataset as well as the clustered data. Both trained models are saved for inference - doing so will help us quantify the benefit of using clustering as opposed to using the full dataset directly for model training. This script will also report on the execution time for these steps. \n",
    "\n",
    "The run benchmark script takes the following arguments:\n",
    "\n",
    "```shell\n",
    "usage: run_benchmarks_train.py [-l LOGFILE] [-i]\n",
    "\n",
    "optional arguments:\n",
    "  -l LOGFILE, --logfile LOGFILE           log file to output benchmarking results to\n",
    "  -i, --intel                             use intel accelerated technologies where available\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e099a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to initialize libs and files\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, './src')\n",
    "from src import benchmark_tools as b_tools\n",
    "\n",
    "jsonfile = './jsons/stock.json'\n",
    "clusteredmodel=\"Clustered_LGBM_Classifier.pkl\"\n",
    "fullmodel=\"Full_LGBM_Classifier.pkl\"\n",
    "\n",
    "#Erase time values from stock json\n",
    "b_tools.init_json(jsonfile)\n",
    "\n",
    "#Remove files\n",
    "if os.path.exists(clusteredmodel):\n",
    "    os.remove(clusteredmodel)\n",
    "\n",
    "if os.path.exists(fullmodel):\n",
    "    os.remove(fullmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f43195",
   "metadata": {},
   "source": [
    "To run with stock technologies, logging the performance to `logs`, we would run (after creating the appropriate environment as above):\n",
    "```shell\n",
    "python ./src/run_benchmarks_train.py -l ./logs/stock_training.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/stock_training.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_train.py' '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38f3f7",
   "metadata": {},
   "source": [
    "The hyperparameter tuning exercise can be run by following the same procedure as described for training. It goes through the same steps prior to the supervised ML portion of the pipeline (ingestion & clustering). Following these, instead of training, the script would perform hyperparameter tuning over a predefined parameter dictionary. Only substitution would be to execute the script `run_benchmarks_hyper.py` instead of `run_benchmarks_train.py`. This execution expects the same arguments as the training case does. \n",
    "\n",
    " Once again, the execution times will be reported and the trained models (using full and clustered data) will be saved for use by the prediction benchmarking script. Following are examples of how the hyperparameter tuning jobs can be triggered.\n",
    "\n",
    "For stock technologies\n",
    "```shell\n",
    "python ./src/run_benchmarks_hyper.py -l ./logs/stock_hyper.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/stock_hyper.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_hyper.py' '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fc46e",
   "metadata": {},
   "source": [
    "The following is a brief description of the outputs of clustering/training/hyperparameter tuning portion of the pipeline:\n",
    "\n",
    "#### **Expected Input Output for Training/Hyperparameter Tuning**\n",
    "\n",
    "**Input:**\n",
    "\n",
    "| **Section**                   | **Expected Input**                   \n",
    "| :---                          | :---                                  \n",
    "| Clustering                    | Portion of the Feature data which is dedicated to the training component of the ML pipeline                            \n",
    "| Training/Hyperparameter tuning | Feature data post clustering as well as the full training feature data along with the respective labels.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Output:**\n",
    "\n",
    "| **Section**                   | **Expected Output**                   | **Comment**\n",
    "| :---                          | :---                                  | :--- \n",
    "| Clustering                    | Cluster id to which each data row is assigned (-1, 0, 1...)                                 | The cluster output is not saved to an output file but appended to the dataframe as a column. The cluster column is then used to filter the data to maximize proportion of fraudulent data. The filtered data is subsequently used for model trainng\n",
    "| Training/Hyperparameter tuning | Model pkl files pertaining to traning using full/clustered data <br> **Clustered_LGBM_Classifier.pkl** <br> **Full_LGBM_Classifier.pkl**     | The pkl files are saved as output in the parent directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec2650",
   "metadata": {},
   "source": [
    "### **Model Inference - Batch**\n",
    "\n",
    "The saved models then can be used for batch inference. For this purpose, we will exectue the  `run_benchmarks_predict.py`. It takes the following arguments: \n",
    "\n",
    "```shell\n",
    "usage: run_bechmarks-predict.py [-l LOGFILE] [-i] [-mc clusteredmodel] [-mc fullmodel] [-s]\n",
    "\n",
    "optional arguments:\n",
    "  -l  --logfile             log file to output benchmarking results to\n",
    "  -i, --intel               use Intel optimized libraries where available\n",
    "  -mc --clusteredmodel      pkl file of model created using clustered data\n",
    "  -mf --fullmodel           pkl file of model created using full data\n",
    "  -s  --streaming           run streaming inference if true\n",
    "```\n",
    "To run with stock technologies, we would run:\n",
    "\n",
    "```shell\n",
    "python ./src/run_benchmarks_predict.py -mc Clustered_LGBM_Classifier.pkl -mf Full_LGBM_Classifier.pkl -l ./logs/stock_batch.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/stock_batch.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_predict.py' '-mc' 'Clustered_LGBM_Classifier.pkl' '-mf' 'Full_LGBM_Classifier.pkl' '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5c175",
   "metadata": {},
   "source": [
    "For streaming inference execute the following command:\n",
    "```shell\n",
    "python ./src/run_benchmarks_predict.py -s -mc Clustered_LGBM_Classifier.pkl -mf Full_LGBM_Classifier.pkl -l ./logs/stock_streaming.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/stock_streaming.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_predict.py' '-s' '-mc' 'Clustered_LGBM_Classifier.pkl' '-mf' 'Full_LGBM_Classifier.pkl' '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b29db8",
   "metadata": {},
   "source": [
    "#### **Expected Input and Output for Inference**\n",
    "\n",
    "**Input:**\n",
    "\n",
    "| **Section**                   | **Expected Input**                   \n",
    "| :---                          | :---                                  \n",
    "| Batch Prediction                   | Portion of the data which is dedicated to testing. The dataset is also duplicated & shuffled to investigate if behavior changes with size. Corresponding labels are also passed as input.\n",
    "| Streaming Prediction               | Similar to batch prediction, but inference is run over a randomly selected single row multiple times to simulate inference on streaming data.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Output:**\n",
    "\n",
    "| **Section**                   | **Expected Output**                   | **Comment**\n",
    "| :---                          | :---                                  | :--- \n",
    "| Batch  Prediction                       | Array of prediction classes of whether a transaction is legitimate or fraudulent (0 for legitimate and 1 for fraudulent). Inference is run for both models, i.e. trained using clustered data as well as full data.                                 | The array is used to calculate f1_scores as well as confusion matrices for the respective models. This will help us compare the performance of the two models. The f1_score is written to the log file and the confusion matrix is saved as a png file in the working directory\n",
    "| Streaming Prediction | Prediction class for a single transaction (0 for legitimate and 1 for fraudulent)     | Primary objective of running streaming inference is to benchmark time taken for prediction. Average time for a single prediction (over 1000 rows) is written to the log file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50507a9e",
   "metadata": {},
   "source": [
    "### **Intel® Clustering + Training/Hyperparameter Tuning**\n",
    "\n",
    "Before running the Intel instructions from the Notebook, the kernel should be set to **[conda-env-FraudDetection_intel-py]**. To set the Notebook to the correct kernel, you can do it by running the following cell (the cell will remain in * but you can continue with the process) or you can do the change manually by selecting **Kernel > Change kernel > Python [conda-env-FraudDetection_intel-py]** on the Notebook’s top menu bar. If the correct kernel was selected, you should be able to see the selected kernel's name on the right side of the Notebook menu bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.restart({kernel_name: \"conda-env-FraudDetection_intel-py\"})\n",
    "element.text('Intel kernel loaded. You can continue executing the next cells.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bb62c",
   "metadata": {},
   "source": [
    "If you want to run the Intel® instructions from a terminal instead of the Notebook, you should follow the commands described on the [README.md](README.md#setting-up-intel-environment) file on the section **Setting up Stock Intel** and activate the **FraudDetection_intel** environment. Copy and paste from the markdown sections to the terminal the lines from this Notebook that run the scripts using the python interpreter, e.g. \"python ./src/run_benchmarks_train.py -i -l ./logs/intel_training.log\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to initialize libs and files\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, './src')\n",
    "from src import benchmark_tools as b_tools\n",
    "\n",
    "jsonfile = './jsons/intel.json'\n",
    "clusteredmodel=\"Clustered_LGBM_Classifier.pkl\"\n",
    "fullmodel=\"Full_LGBM_Classifier.pkl\"\n",
    "\n",
    "#Erase time values from stock json\n",
    "b_tools.init_json(jsonfile)\n",
    "\n",
    "#Remove files\n",
    "if os.path.exists(clusteredmodel):\n",
    "    os.remove(clusteredmodel)\n",
    "\n",
    "if os.path.exists(fullmodel):\n",
    "    os.remove(fullmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0bbfad",
   "metadata": {},
   "source": [
    "There will be only one change here compared to the command for training a model with the stock packages, the addition of an argument (-i) which enables the use of intel-optimized packages, which in case of training/hyperparameter tuning would be Intel Extension for Scikit-Learn. To run with intel technologies, logging the performance to `logs`, we would run (after activating the intel environment):\n",
    "\n",
    "```shell\n",
    "python ./src/run_benchmarks_train.py -i -l ./logs/intel_training.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c643a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/intel_training.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_train.py' '-i' '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba18a1",
   "metadata": {},
   "source": [
    "For hyperparameter tuning, execute the following command:\n",
    "\n",
    "```shell\n",
    "python ./src/run_benchmarks_hyper.py -i -l ./logs/intel_hyper.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83776908",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/intel_hyper.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_hyper.py' '-i' '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc3a69",
   "metadata": {},
   "source": [
    "### **Model Inference**\n",
    "\n",
    "Model inference in an intel environment will leverage the daal4py module which will convert the existing LGBM model into an optimized version. The optimized model will then be used for batch/streaming prediction. The benefit of using this daal4py version of the model is key to the solution as it means faster inference times, which we will see from the plots in the results section.\n",
    "\n",
    "For batch inference, execute the following command:\n",
    "```shell\n",
    "python ./src/run_benchmarks_predict.py -i -mc Clustered_LGBM_Classifier.pkl -mf Full_LGBM_Classifier.pkl -l ./logs/intel_batch.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac3e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/intel_batch.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_predict.py' '-i' '-mc' $clusteredmodel '-mf' $fullmodel '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ae86c",
   "metadata": {},
   "source": [
    "For streaming inference execute the following command\n",
    "```shell\n",
    "python ./src/run_benchmarks_predict.py -s -i -mc Clustered_LGBM_Classifier.pkl -mf Full_LGBM_Classifier.pkl -l ./logs/intel_streaming.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log='./logs/intel_streaming.log'\n",
    "!rm $log 2>/dev/null\n",
    "%run './src/run_benchmarks_predict.py' '-s' '-i' '-mc' $clusteredmodel '-mf' $fullmodel '-l' $log\n",
    "\n",
    "b_tools.parse_logs(log, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0a7f0",
   "metadata": {},
   "source": [
    "## **Comparing Performance Benefits**\n",
    "\n",
    "In this section, we illustrate the benchmarking results comparing the Intel-optimized libraries vs the stock alternative as well as the performance of the two LGBM models (one trained using post-clustering data and one trained using the full dataset). The data for the comparison is obtained from the log files generated when executing the previous cells of the Notebook.\n",
    "It should be noted that to obtain the results on the final cell both, the Intel® and Stock, instructions should have already been executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see the speed comparisons between Stock vs Intel versions,\n",
    "#run once Stock and Intel Jupyter Notebooks have been runned.\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, './src')\n",
    "from src import benchmark_tools as b_tools\n",
    "b_tools.plot_log_times('./jsons/stock.json', './jsons/intel.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FraudDetection_intel]",
   "language": "python",
   "name": "conda-env-FraudDetection_intel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
